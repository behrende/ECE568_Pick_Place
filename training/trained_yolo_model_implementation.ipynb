{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This page briefly introduces how to train a YOLO model in local MAC OS laptop."
      ],
      "metadata": {
        "id": "oKtrI53hkfVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Virtual Environment Creation\n",
        "Create and then enter a virtual environment yolo_v8n"
      ],
      "metadata": {
        "id": "n1ISL_gtkuyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python3 -m venv yolo_v8n\n",
        "source ~/yolo_v8n/bin/activate"
      ],
      "metadata": {
        "id": "IFj1B6mmlNvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements Installation"
      ],
      "metadata": {
        "id": "wT9DSNWJna86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip\n",
        "pip install ultralytics\n",
        "pip install Numpy==1.26.4"
      ],
      "metadata": {
        "id": "eH_iRbwfmZkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO Model Test\n",
        "To test the trained model using the camera on PC, place the trained model in the same folder with the python test script. For example, yolo_v11n.pt is the trained model; and yolov11n_test.py is the test script; put these two files in the same folder."
      ],
      "metadata": {
        "id": "m9ZmgCav4gTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "model = YOLO(\"yolo_v11n.pt\")\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    results = model(frame)\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0]\n",
        "            confidence = box.conf[0]\n",
        "            class_id = int(box.cls[0])\n",
        "\n",
        "            x1,y1,x2,y2 = map(int, [x1,y1,x2,y2])\n",
        "            confidence = float(confidence)\n",
        "            label = f\"Class {class_id} ({confidence:.2f})\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "            print(f\"Object Detected: Class {class_id} - Box: ({x1}, {y1}, {x2}, {y2}) - Confidence: {confidence:.2f}\")\n",
        "            \"\"\"\n",
        "            (x1,y1) -- vertex of rectangle\n",
        "            (x2,y2) -- vertex of rectangle opposite to (x1,y1)\n",
        "            Class 0: Apple\n",
        "            Class 1: Banana\n",
        "            Class 2: Grapes\n",
        "            Class 3: Kiwi\n",
        "            Class 4: Mango\n",
        "            Class 5: Orange\n",
        "            Class 6: Pineapple\n",
        "            Class 7: Sugerapple\n",
        "            Class 8: Watermelon\n",
        "            \"\"\"\n",
        "    cv2.imshow(\"YOLOv11n Detection\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "w9TJBL_f5XbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output in the terminal if an apple is detected."
      ],
      "metadata": {
        "id": "4gD1XKUZBI63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0: 384x640 1 Apple, 65.1ms\n",
        "# Speed: 2.2ms preprocess, 65.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
        "# Object Detected: Class 0 - Box: (188, 82, 709, 654) - Confidence: 0.94"
      ],
      "metadata": {
        "id": "dpBuTe4ZBRgF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}