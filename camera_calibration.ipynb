{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Camera calibration\n",
        "Camera calibration consists of two steps: intrinsic calibration and hand-eye calibration."
      ],
      "metadata": {
        "id": "t8IOTeCLNIXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of intrinsic calibration is to compute the intrinsic parameters of the camera (the focal length, the optical center)and distortion parameters (radial distortion and tangential distortion coefficient). These parameters will be used to convert the pixel coordinates to real world coordinates. A general procedure is listed in the following:\n",
        "\n",
        "\n",
        "1.   Attached the camera to the end-effector of the robot arm\n",
        "2.   Print an 8x8 chessboard(or something similar), each square with a known size;\n",
        "3. Fix the pattern on the flat surface\n",
        "4. Use OpenCV to take 15-25 images from different angles and distances\n",
        "5. Process the images using OpenCV library to obtain the intrinsic and distortion parameters.\n",
        "\n",
        "Some python script template are listed in the following for reference.\n",
        "\n"
      ],
      "metadata": {
        "id": "CD-r1OPxPtz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this script is used for image collection\n",
        "import cv2\n",
        "cap = cv2.VideoCapture(0)\n",
        "i = 0\n",
        "img_name_1 = \"calib_img_\"\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    cv2.imshow('frame', frame)\n",
        "\n",
        "    if cv2.waitKey(1) == ord('s'):\n",
        "        i += 1\n",
        "        img_name = img_name_1 + str(i) + \".jpg\"\n",
        "        cv2.imwrite(img_name, frame)\n",
        "    elif cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "IuW1OGXTQ10R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this script is used for calculation of the intrinsic and distortion parameters\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "# Chessboard dimensions\n",
        "chessboard_size = (8, 8)\n",
        "square_size = 20  # mm\n",
        "\n",
        "# Prepare object points (0,0,0), (1,0,0) ... scaled by square size\n",
        "objp = np.zeros((np.prod(chessboard_size), 3), np.float32)\n",
        "objp[:, :2] = np.indices(chessboard_size).T.reshape(-1, 2)\n",
        "objp *= square_size\n",
        "\n",
        "objpoints = []\n",
        "imgpoints = []\n",
        "\n",
        "images = glob.glob('calib_img_*.jpg')\n",
        "for fname in images:\n",
        "    img = cv2.imread(fname)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)\n",
        "    if ret:\n",
        "        objpoints.append(objp)\n",
        "        imgpoints.append(corners)\n",
        "\n",
        "ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
        "\n",
        "with open(\"camera_calibration.pkl\", \"wb\") as f:\n",
        "    pickle.dump((K, dist), f)\n",
        "\n",
        "print(\"Calibration complete. Camera matrix:\\n\", K)\n",
        "print(\"Distortion coefficients:\\n\", dist)"
      ],
      "metadata": {
        "id": "nrizCRqDRaVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of Hand-Eye Calibration is to relate what the camera sees to where the robot end effector moves. It is a process to determine the relative position and orientation of a robot-mounted camera with respect to the robot's end-effector.\n",
        "\n",
        "A general procedure is listed in the following:\n",
        "1. Move the robot to at least 10 different poses, preferably with some rotation.\n",
        "2. At each pose, take a picture of the chessboard or printed pattern\n",
        "3. Record the end-effector pose (transformation matrix) in base frame\n",
        "4. solve hand-eye calibration\n",
        "\n",
        "A script template is provided in the following for reference."
      ],
      "metadata": {
        "id": "8PsUxFTlRvF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This step post-processes all the images captured in different end-effector poses\n",
        "# By utilizing the intrinsic parameters and distortion coefficients obtained in the\n",
        "# intrinsic calibration, the transformation matrix of target pose in the camera frame,\n",
        "# T_target2cam(R_target2cam, t_target2cam) for each pose is obtained.\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Chessboard dimensions\n",
        "chessboard_size = (8, 8)\n",
        "square_size = 20  # mm\n",
        "\n",
        "# Prepare object points (3D points in target frame)\n",
        "objp = np.zeros((np.prod(checkerboard_size), 3), np.float32)\n",
        "objp[:, :2] = np.mgrid[0:checkerboard_size[0], 0:checkerboard_size[1]].T.reshape(-1, 2)\n",
        "objp *= square_size  # scale to real world units\n",
        "\n",
        "# Load image and find corners\n",
        "img = cv2.imread('checkerboard_image.png')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "ret, corners = cv2.findChessboardCorners(gray, checkerboard_size)\n",
        "\n",
        "if ret:\n",
        "    # Refine corner detection\n",
        "    corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1),\n",
        "        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
        "\n",
        "    # Camera intrinsics (from intrinsic calibration mentioned above)\n",
        "    K = ...  # 3x3 intrinsic matrix\n",
        "    dist_coeffs = ...  # distortion coefficients\n",
        "\n",
        "    # Solve PnP to get target pose in camera frame\n",
        "    ret, rvec, tvec = cv2.solvePnP(objp, corners, K, dist_coeffs)\n",
        "\n",
        "    # Convert rotation vector to rotation matrix, and position vector\n",
        "    R_target2cam, _ = cv2.Rodrigues(rvec)\n",
        "    t_target2cam = tvec\n"
      ],
      "metadata": {
        "id": "yHSr6sboK1q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This step estimates the transmation matrix T_cam2gripper (R_cam2gripper, t_cam2gripper),\n",
        "# based on the transformation matrix T_gripper2base (R_gripper2base, t_gripper2base) and\n",
        "# the transformation matrix T_target2cam(R_target2cam, t_target2cam).\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Lists of 3x3 Rotation matrix and 3x1 vectors\n",
        "# both can be obtained from transformation matrix determined via\n",
        "# forward kinematics\n",
        "R_gripper2base = []\n",
        "t_gripper2base = []\n",
        "# Append all the data here...\n",
        "# R_gripper2base.append(R_base_ee)\n",
        "# t_gripper2base.append(t_base_ee)\n",
        "\n",
        "R_target2cam = []     # from solvePnP\n",
        "t_target2cam = []\n",
        "# Append all the data here\n",
        "# R_target2cam.append(R_cam_target)\n",
        "# t_target2cam.append(t_cam_target)\n",
        "\n",
        "R_cam2gripper, t_cam2gripper = cv2.calibrateHandEye(\n",
        "    R_gripper2base, t_gripper2base,\n",
        "    R_target2cam, t_target2cam,\n",
        "    method=cv2.CALIB_HAND_EYE_TSAI\n",
        ")"
      ],
      "metadata": {
        "id": "reVKKQOLU23L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}